const char* const templates_GB_jit_AxB_dot3_phase3_vsvs_cu = "templates/GB_jit_AxB_dot3_phase3_vsvs.cu\n"
"//******************************************************************************\n"
"//  Sparse dot version of Matrix-Matrix multiply with mask \n"
"//  Each thread in this kernel is responsible for m vector-pairs(x,y), \n"
"//  finding intersections and producting the final dot product for each\n"
"//  using a serial merge algorithm on the sparse vectors. \n"
"//  m = 256/sz, where sz is in {4, 16, 64, 256}\n"
"//  For a vector-pair, sz = xnz + ynz \n"
"//  Template on <T_C, T_M, T_A, T_B>\n"
"//  Parameters:\n"
"\n"
"//  int64_t start          <- start of vector pairs for this kernel\n"
"//  int64_t end            <- end of vector pairs for this kernel\n"
"//  int64_t *Bucket        <- array of pair indices for all kernels \n"
"//  matrix<T_C> *C         <- result matrix \n"
"//  matrix<T_M> *M         <- mask matrix\n"
"//  matrix<T_A> *A         <- input matrix A\n"
"//  matrix<T_B> *B         <- input matrix B\n"
"//  int sz                 <- nnz of very sparse vectors\n"
"\n"
"//  Blocksize is 1024, uses warp and block reductions to count zombies produced.\n"
"//******************************************************************************\n"
"#define GB_KERNEL\n"
"#include <limits>\n"
"#include <cstdint>\n"
"#include <stdio.h>\n"
"#include <cooperative_groups.h>\n"
"#include \"matrix.h\"\n"
"\n"
"using namespace cooperative_groups;\n"
"\n"
"template< typename T, int tile_sz>\n"
"__inline__ __device__ \n"
"T warp_ReduceSumPlus( thread_block_tile<tile_sz> g, T val)\n"
"{\n"
"    // Each iteration halves the number of active threads\n"
"    // Each thread adds its partial sum[i] to sum[lane+i]\n"
"    for (int i = g.size() / 2; i > 0; i /= 2) {\n"
"        //printf(\"thd%d   %d OP %d is %d\\n\", threadIdx.x, val, fold, OP( val, fold));\n"
"        val +=  g.shfl_down( val, i);\n"
"    }\n"
"    return val; // note: only thread 0 will return full sum\n"
"}\n"
"\n"
"template< typename T, int tile_sz>\n"
"__inline__ __device__ \n"
"T warp_Reduce( thread_block_tile<tile_sz> g, T val)\n"
"{\n"
"    // Each iteration halves the number of active threads\n"
"    // Each thread adds its partial sum[i] to sum[lane+i]\n"
"    for (int i = g.size() / 2; i > 0; i /= 2) {\n"
"        T next = g.shfl_down( val, i) ;\n"
"        val = GB_ADD( sum, next ) ; \n"
"    }\n"
"    return val; // note: only thread 0 will return full sum\n"
"}\n"
"\n"
"template<typename T, int warpSize>\n"
"__inline__ __device__\n"
"T block_ReduceSum(thread_block g, T val)\n"
"{\n"
"  static __shared__ T shared[warpSize]; // Shared mem for 32 partial sums\n"
"  int lane = threadIdx.x & 31 ; // % warpSize;\n"
"  int wid  = threadIdx.x >> 5 ; // / warpSize;\n"
"  thread_block_tile<warpSize> tile = tiled_partition<warpSize>( g );\n"
"\n"
"  // Each warp performs partial reduction\n"
"  val = warp_ReduceSumPlus<T, warpSize>( tile, val);    \n"
"\n"
"  // Wait for all partial reductions\n"
"  if (lane==0) shared[wid]=val; // Write reduced value to shared memory\n"
"  __syncthreads();              // Wait for all partial reductions\n"
"\n"
"  if (wid > 0 || gridDim.x == 1 ) return val;\n"
"\n"
"  //read from shared memory only if that warp existed\n"
"  val = (threadIdx.x <  (blockDim.x / warpSize ) ) ? shared[lane] : 0;\n"
"  //printf(\"thd%d warp loaded val = %d\\n\", threadIdx.x, lane, val);\n"
"\n"
"  if (wid==0) val = warp_ReduceSumPlus<T, warpSize>( tile, val); //Final reduce within first warp\n"
"\n"
"  return val;\n"
"}\n"
"\n"
"template< typename T_C, typename T_A, typename T_B, typename T_X, typename T_Y, typename T_Z>\n"
"__global__ void AxB_dot3_phase3_vsvs\n"
"( \n"
"  const int64_t start, \n"
"  const int64_t end,\n"
"  const int64_t *__restrict__ Bucket, \n"
"  const GrB_Matrix C, \n"
"  const GrB_Matrix M, \n"
"  const GrB_Matrix A, \n"
"  const GrB_Matrix B,\n"
"  const int sz \n"
")\n"
"{\n"
"   int dots = end - start;\n"
"   // sz = expected non-zeros per dot \n"
"   /*\n"
"   int m = (gridDim.x*blockDim.x)*256/sz;\n"
"   int dpt = (nvecs+ gridDim.x*blockDim.x -1)/(gridDim.x*blockDim.x);\n"
"   m = dpt < m ? dpt : m;\n"
"   \n"
"   int dots = (nvecs +m -1)/m; \n"
"   */\n"
"   const T_A *__restrict__ Ax = (T_A *)A->x  ;\n"
"   const T_B *__restrict__ Bx = (T_B *)B->x  ;\n"
"   T_C *__restrict__ Cx = (T_C *)C->x  ;\n"
"   int64_t *__restrict__ Ci = C->i ;\n"
"   const int64_t *__restrict__ Mi = M->i ;\n"
"   const int64_t *__restrict__ Ai = A->i ;\n"
"   const int64_t *__restrict__ Bi = B->i ;\n"
"   const int64_t *__restrict__ Ap = A->p ;\n"
"   const int64_t *__restrict__ Bp = B->p ;\n"
"\n"
"   int pfirst, plast;\n"
"\n"
"   GB_PARTITION (pfirst, plast, dots, blockIdx.x, gridDim.x ) ;\n"
"   /* \n"
"   if( threadIdx.x ==0 )\n"
"   {\n"
"      printf(\"block%d %d dots/thrd, start,end = %ld,%ld pf,pl=%d,%d blockDim=%d\\n\",\n"
"               blockIdx.x, (dots + blockDim.x*gridDim.x -1)/(blockDim.x*gridDim.x), \n"
"               start, end, pfirst, plast, blockDim.x);\n"
"   }\n"
"   __syncthreads();\n"
"   */\n"
"   \n"
"\n"
"   int zc = 0 ;\n"
"     \n"
"   int64_t pair_id;\n"
"\n"
"   //for ( int tid= threadIdx.x +blockDim.x*blockIdx.x;\n"
"   //          tid < dots;\n"
"   //          tid += blockDim.x * gridDim.x)\n"
"   for ( int tid = pfirst+ threadIdx.x ;\n"
"             tid < plast;\n"
"             tid += blockDim.x )\n"
"   {\n"
"\n"
"         pair_id = Bucket[ start + tid ]; \n"
"\n"
"         int64_t i = Mi [pair_id] ;\n"
"         int64_t j = Ci [pair_id]>>4 ; \n"
"\n"
"         int64_t pA       = Ap[i] ;\n"
"         int64_t pA_end   = Ap[i+1] ;\n"
"         int64_t pB       = Bp[j] ; \n"
"         int64_t pB_end   = Bp[j+1] ; \n"
"\n"
"         T_A aki;\n"
"         T_B bkj;\n"
"         T_Z cij ;\n"
"\n"
"         bool cij_exists = false;\n"
"\n"
"         while (pA < pA_end && pB < pB_end)\n"
"         {\n"
"            int64_t ia = Ai [pA] ;\n"
"            int64_t ib = Bi [pB] ;\n"
"            if( ia == ib)\n"
"            { \n"
"                // A(k,i) and B(k,j) are the next entries to merge\n"
"                #if defined ( GB_PHASE_1_OF_2 )\n"
"                cij_exists = true ;\n"
"                break ;\n"
"                #else\n"
"                GB_DOT_MERGE ;\n"
"                //GB_DOT_TERMINAL (cij) ;         // break if cij == terminal\n"
"                pA++ ;\n"
"                pB++ ;\n"
"                #endif\n"
"            }\n"
"            else \n"
"            {\n"
"                // A(ia,i) appears before B(ib,j)\n"
"                pA += ( ia < ib);\n"
"                // B(ib,j) appears before A(ia,i)\n"
"                pB += ( ib < ia);\n"
"            }\n"
"         }\n"
"         if (cij_exists){\n"
"            GB_PUTC ( Ci[pair_id] = i ) ;\n"
"            GB_PUTC ( Cx[pair_id] = (T_C)cij ) ;\n"
"         }\n"
"         else{\n"
"            //printf(\" %lld, %lld is zombie %d!\\n\",i,j,zc);\n"
"            zc++; \n"
"            GB_PUTC( Ci[pair_id] = GB_FLIP( i ) ) ;\n"
"         }\n"
"   }\n"
"  \n"
"   __syncthreads();\n"
"\n"
"   //printf(\"thd%d zombie count = %d\\n\",threadIdx.x,zc);\n"
"   zc = block_ReduceSum<int , 32>( this_thread_block(), zc); \n"
"   __syncthreads();\n"
"\n"
"   if( threadIdx.x == 0 && zc > 0) {\n"
"      //printf(\"block%d zombie count = %d\\n\", blockIdx.x, zc);\n"
"      atomicAdd( (unsigned long long int*)&(C->nzombies), (unsigned long long int)zc);\n"
"      //C->nzombies += (unsigned long long int)zc;\n"
"      //printf(\"blk:%d Czombie = %lld\\n\", blockIdx.x,C->nzombies);\n"
"   }\n"
"   \n"
"}\n"
;
