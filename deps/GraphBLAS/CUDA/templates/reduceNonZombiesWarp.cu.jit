const char* const templates_reduceNonZombiesWarp_cu = "templates/reduceNonZombiesWarp.cu\n"
"//------------------------------------------------------------------------------\n"
"// reduceUnrolled.cu\n"
"//------------------------------------------------------------------------------\n"
"\n"
"// The reduceUnrolled CUDA kernel reduces an array g_idata of size n, of any\n"
"// type T, to an array g_odata of size grid.x.  Each threadblock (blockIdx.x)\n"
"// reduces its portion of g_idata to a single scalar, g_odata [blockIdx.x].\n"
"\n"
"// Both the grid and block are 1D, so blockDim.x is the # threads in a\n"
"// threadblock, and the # of threadblocks is grid.x\n"
"\n"
"// Let b = blockIdx.x, and let s be blockDim.x.\n"
"// Each threadblock owns s*8 contiguous items in the input data.\n"
"\n"
"// Thus, threadblock b owns g_idata [b*s*8 ... min(n,(b+1)*s*8-1)].  It's job\n"
"// is to reduce this data to a scalar, and write it to g_odata [b].\n"
"\n"
"#define GB_KERNEL\n"
"#include <limits>\n"
"#include <cstdint>\n"
"#include <cooperative_groups.h>\n"
"\n"
"using namespace cooperative_groups;\n"
"\n"
"template< typename T, int tile_sz>\n"
"__inline__ __device__ \n"
"T warp_ReduceSum( thread_block_tile<tile_sz> g, T val)\n"
"{\n"
"    // Each iteration halves the number of active threads\n"
"    // Each thread adds its partial sum[i] to sum[lane+i]\n"
"    for (int i = g.size() / 2; i > 0; i /= 2) {\n"
"        T fold = g.shfl_down( val, i);\n"
"        //printf(\"thd%d   %d OP %d is %d\\n\", threadIdx.x, val, fold, OP( val, fold));\n"
"        val = GB_ADD( val, fold );\n"
"    }\n"
"    //if (threadIdx.x ==0) printf(\"thd%d single warp sum is %d\\n\", threadIdx.x,  val);\n"
"    return val; // note: only thread 0 will return full sum\n"
"}\n"
"\n"
"template<typename T, int warpSize>\n"
"__inline__ __device__\n"
"T block_ReduceSum(thread_block g, T val)\n"
"{\n"
"  static __shared__ T shared[warpSize]; // Shared mem for 32 partial sums\n"
"  int lane = threadIdx.x & 31 ; // % warpSize;\n"
"  int wid  = threadIdx.x >> 5 ; // / warpSize;\n"
"  thread_block_tile<warpSize> tile = tiled_partition<warpSize>( g );\n"
"\n"
"  // Each warp performs partial reduction\n"
"  val = warp_ReduceSum<T, warpSize>( tile, val);    \n"
"\n"
"  // Wait for all partial reductions\n"
"  if (lane==0) { \n"
"     //printf(\"thd%d warp%d sum is %d\\n\", threadIdx.x, wid, val);\n"
"     shared[wid] = val; // Write reduced value to shared memory\n"
"     //printf(\"thd%d stored warp%d sum %d\\n\", threadIdx.x, wid, val);\n"
"  }\n"
"  __syncthreads();              // Wait for all partial reductions\n"
"\n"
"  if (wid > 0 ) return val;\n"
"  //read from shared memory only if that warp existed\n"
"  else { \n"
"    val = (threadIdx.x < (blockDim.x / warpSize) ) ? shared[lane] : GB_IDENTITY ;\n"
"    //if (lane < (blockDim.x/ warpSize) ) printf(\"thd%d warp%d loaded val = %d\\n\", threadIdx.x, lane, val);\n"
"    val = warp_ReduceSum<T, warpSize>( tile, val); //Final reduce within first warp\n"
"  }\n"
"\n"
"  return val;\n"
"}\n"
"\n"
"template< typename T>\n"
"__global__ void reduceNonZombiesWarp\n"
"(\n"
"    int64_t *index,  // array of size n\n"
"    T *g_idata,      // array of size n\n"
"    T *g_odata,      // array of size grid.x\n"
"    unsigned int N\n"
")\n"
"{\n"
"    // set thread ID\n"
"    int tid = threadIdx.x ;\n"
"\n"
"    // each thread tid reduces its result into sum\n"
"    T sum = (T) GB_IDENTITY;\n"
"\n"
"    for(int i = blockIdx.x * blockDim.x + threadIdx.x; \n"
"        i < N; \n"
"        i += blockDim.x * gridDim.x) {\n"
"        if ( index[i] < 0) continue;\n"
"        T fold = g_idata[i];\n"
"        sum = GB_ADD( sum, fold );\n"
"    }\n"
"    //printf(\"thd%d  sum is %d\\n\", threadIdx.x + blockDim.x*blockIdx.x, sum);\n"
"    __syncthreads();\n"
"    //--------------------------------------------------------------------------\n"
"    // reduce work [0..s-1] to a single scalar\n"
"    //--------------------------------------------------------------------------\n"
"    // this assumes blockDim is a multiple of 32\n"
"    sum = block_ReduceSum< T, 32 >( this_thread_block(), sum) ; \n"
"\n"
"    // write result for this block to global mem\n"
"    if (tid == 0)\n"
"    {\n"
"        g_odata [blockIdx.x] = sum ;\n"
"    }\n"
"}\n"
"\n"
;
