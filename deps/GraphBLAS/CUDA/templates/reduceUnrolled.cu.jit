const char* const templates_reduceUnrolled_cu = "templates/reduceUnrolled.cu\n"
"//------------------------------------------------------------------------------\n"
"// reduceUnrolled.cu\n"
"//------------------------------------------------------------------------------\n"
"\n"
"// The reduceUnrolled CUDA kernel reduces an array g_idata of size n, of any\n"
"// type T, to an array g_odata of size grid.x.  Each threadblock (blockIdx.x)\n"
"// reduces its portion of g_idata to a single scalar, g_odata [blockIdx.x].\n"
"\n"
"// Both the grid and block are 1D, so blockDim.x is the # threads in a\n"
"// threadblock, and the # of threadblocks is grid.x\n"
"\n"
"// Let b = blockIdx.x, and let s be blockDim.x.\n"
"// Each threadblock owns s*8 contiguous items in the input data.\n"
"\n"
"// Thus, threadblock b owns g_idata [b*s*8 ... min(n,(b+1)*s*8-1)].  It's job\n"
"// is to reduce this data to a scalar, and write it to g_odata [b].\n"
"\n"
"#include \"myOp.h\"\n"
"#include <cooperative_groups.h>\n"
"#include \"GB_cuda.h\"\n"
"\n"
"GrB_Matrix Stuff ;  // hack hack hack\n"
"\n"
"using namespace cooperative_groups;\n"
"\n"
"template< typename T, int tile_sz>\n"
"__inline__ __device__ \n"
"T warp_ReduceSum( thread_block_tile<tile_sz> g, T val)\n"
"{\n"
"    // Each iteration halves the number of active threads\n"
"    // Each thread adds its partial sum[i] to sum[lane+i]\n"
"    for (int i = g.size() / 2; i > 0; i /= 2) {\n"
"        T fold = g.shfl_down( val, i);\n"
"        //printf(\"thd%d   %d OP %d is %d\\n\", threadIdx.x, val, fold, OP( val, fold));\n"
"        val = OP( val, fold );\n"
"    }\n"
"    //if (threadIdx.x ==0) printf(\"thd%d single warp sum is %d\\n\", threadIdx.x,  val);\n"
"    return val; // note: only thread 0 will return full sum\n"
"}\n"
"\n"
"template<typename T, int warpSize>\n"
"__inline__ __device__\n"
"T block_ReduceSum(thread_block g, T val)\n"
"{\n"
"  static __shared__ T shared[warpSize]; // Shared mem for 32 partial sums\n"
"  int lane = threadIdx.x % warpSize;\n"
"  int wid = threadIdx.x / warpSize;\n"
"  thread_block_tile<warpSize> tile = tiled_partition<warpSize>( g );\n"
"\n"
"  // Each warp performs partial reduction\n"
"  val = warp_ReduceSum<T, warpSize>( tile, val);    \n"
"\n"
"  // Wait for all partial reductions\n"
"  if (lane==0) { \n"
"     //printf(\"thd%d warp%d sum is %d\\n\", threadIdx.x, wid, val);\n"
"     shared[wid]=val; // Write reduced value to shared memory\n"
"     //printf(\"thd%d stored warp %d sum %d\\n\", threadIdx.x, wid, val);\n"
"  }\n"
"  g.sync();              // Wait for all partial reductions\n"
"\n"
"  if (wid > 0 || gridDim.x == 1 ) return val;\n"
"  //read from shared memory only if that warp existed\n"
"  val = (threadIdx.x < blockDim.x / warpSize) ? shared[lane] : MONOID_IDENTITY;\n"
"  //printf(\"thd%d warp loaded val = %d\\n\", threadIdx.x, lane, val);\n"
"\n"
"  \n"
"  if (wid==0) val = warp_ReduceSum<T, warpSize>( tile, val); //Final reduce within first warp\n"
"\n"
"  return val;\n"
"}\n"
"\n"
"template< typename T>\n"
"__global__ void reduceUnrolled\n"
"(\n"
"    T *g_idata,     // array of size n\n"
"    T *g_odata,     // array of size grid.x\n"
"    unsigned int n\n"
")\n"
"{\n"
"    // set thread ID\n"
"    unsigned int tid = threadIdx.x ;\n"
"\n"
"    // this threadblock b owns g_idata [block_start ... block_end-1]\n"
"    unsigned long int s = blockDim.x ;\n"
"    unsigned long int b = blockIdx.x ;\n"
"    unsigned long int block_start = b * s * 8 ;\n"
"    unsigned long int block_end   = (b + 1) * s * 8 ;\n"
"\n"
"    /*\n"
"    if (tid == 0)\n"
"    {\n"
"        printf (\"block %d: [%lu ... %ld]\\n\", b, block_start, block_end-1) ;\n"
"    }\n"
"    */\n"
"\n"
"    /*\n"
"    if (tid == 0 && b == 0)\n"
"    {\n"
"        printf (\"type is size %d\\n\", sizeof (T)) ;\n"
"        for (int k = 0 ; k < n ; k++) printf (\"%4d: %g\\n\", k, (double) g_idata [k]) ;\n"
"        printf (\"\\n\") ;\n"
"    }\n"
"    */\n"
"\n"
"    // nothing to do\n"
"    if (block_start > block_end) { if (tid == 0) printf (\"bye!\\n\") ; return ; }\n"
"\n"
"    // convert global data pointer to the local pointer of this block\n"
"    T *idata = g_idata + block_start ;\n"
"\n"
"    T x0, x1, x2, x3, x4, x5, x6, x7 ;\n"
"\n"
"    if (block_end <= n)\n"
"    {\n"
"        // unrolling 8\n"
"        x0 = idata [tid] ;\n"
"        x1 = idata [tid +     s] ;\n"
"        x2 = idata [tid + 2 * s] ;\n"
"        x3 = idata [tid + 3 * s] ;\n"
"        x4 = idata [tid + 4 * s] ;\n"
"        x5 = idata [tid + 5 * s] ;\n"
"        x6 = idata [tid + 6 * s] ;\n"
"        x7 = idata [tid + 7 * s] ;\n"
"\n"
"        /*\n"
"        if (b == 0)\n"
"        {\n"
"            printf (\"block zero: here is tid %2d : %g %g %g %g %g %g %g %g \\n\", tid,\n"
"                (double) x0, (double) x1, (double) x2, (double) x3,\n"
"                (double) x4, (double) x5, (double) x6, (double) x7) ;\n"
"        }\n"
"        */\n"
"\n"
"    }\n"
"    else\n"
"    {\n"
"        // the last block has size less than 8*s\n"
"        #define IDATA(i) ((i < lastblocksize) ? idata [i] : MONOID_IDENTITY)\n"
"        int lastblocksize = n - block_start ;\n"
"        x0 = IDATA (tid) ;\n"
"        x1 = IDATA (tid +     s) ;\n"
"        x2 = IDATA (tid + 2 * s) ;\n"
"        x3 = IDATA (tid + 3 * s) ;\n"
"        x4 = IDATA (tid + 4 * s) ;\n"
"        x5 = IDATA (tid + 5 * s) ;\n"
"        x6 = IDATA (tid + 6 * s) ;\n"
"        x7 = IDATA (tid + 7 * s) ;\n"
"    }\n"
"    T sum;\n"
"    //work [tid] = x0 + x1 + x2 + x3 + x4 + x5 + x6 + x7 ;\n"
"    sum = OP( x0 ,OP( x1, OP( x2, OP( x3,\n"
"                 OP( x4, OP( x5 , OP( x6 , x7))))))) ;\n"
"\n"
"        /*\n"
"        if (b == 0)\n"
"        {\n"
"            printf (\"block zero: still is tid %2d : %g %g %g %g %g %g %g %g \\n\", tid,\n"
"                (double) x0, (double) x1, (double) x2, (double) x3,\n"
"                (double) x4, (double) x5, (double) x6, (double) x7) ;\n"
"        }\n"
"\n"
"        if (b == 0)\n"
"        {\n"
"            printf (\"block zero: here is tid %d result %g  is %g\\n\",\n"
"            tid, (double) work [tid],\n"
"            (double) (x0 + x1 + x2 + x3 + x4 + x5 + x6 + x7)) ;\n"
"        }\n"
"        */\n"
"\n"
"    __syncthreads ( ) ;\n"
"\n"
"    //--------------------------------------------------------------------------\n"
"    // reduce work [0..s-1] to a single scalar\n"
"    //--------------------------------------------------------------------------\n"
"\n"
"    // This assumes that s is a power of 2 and <= 1024, and at least 32\n"
"    // This assumes blockDim is a multiple of 32\n"
"    sum = block_ReduceSum<T , 32>( this_thread_block(), sum); \n"
"\n"
"    // write result for this block to global mem\n"
"    if (tid == 0)\n"
"    {\n"
"        // printf (\"final %d : %g\\n\", b, (double) work [0]) ;\n"
"        g_odata [b] = sum ;\n"
"    }\n"
"}\n"
"\n"
;
