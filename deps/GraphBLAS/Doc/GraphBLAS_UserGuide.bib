@inproceedings{BulucGilbert08,
        author={Bulu\c{c}, A. and Gilbert, J.},
        booktitle={IPDPS'80: 2008 IEEE Intl. Symp. on Parallel and Distributed Processing}, 
        title={On the representation and multiplication of hypersparse matrices}, 
        year={2008}, 
        volume={}, 
        number={}, 
        pages={1-11}, 
        note={\href{https://dx.doi.org/10.1109/IPDPS.2008.4536313}{https://dx.doi.org/10.1109/IPDPS.2008.4536313}},
        month={April},
}

@article{BulucGilbert12,
    author = {Bulu\c{c}, A. and Gilbert, J.},
    title = {Parallel Sparse Matrix-Matrix Multiplication and Indexing: Implementation and Experiments},
    journal = {SIAM Journal on Scientific Computing},
    volume = {34},
    number = {4},
    pages = {C170-C191},
    year = {2012},
    doi = {10.1137/110848244},
    note ={\href{https://dx.doi.org/10.1137/110848244}{https://dx.doi.org/10.1137/110848244}},
}



@book{Davis06book,
        author={Davis, T. A.},
        title={Direct Methods for Sparse Linear Systems},
        publisher={SIAM},
        year={2006},
        address={Philadelphia, PA},
        annotate={\footnotesize
        Provides a basic overview of many sparse matrix algorithms
        and a simple sparse matrix data structure.  The sparse data structure
        used in the book is much like the one in both MATLAB and
        SuiteSparse:GraphBLAS.  A series of 42 lectures are available on
        YouTube; see the link at
        \href{http://faculty.cse.tamu.edu/davis/publications.html}
        {http://faculty.cse.tamu.edu/davis/publications.html}
        For the book, see
        \href{https://dx.doi.org/10.1137/1.9780898718881}{https://dx.doi.org/10.1137/1.9780898718881}},
}


@article{DavisRajamanickamSidLakhdar16,
        author={Davis, T. A. and Rajamanickam, S. and Sid-Lakhdar, W. M.},
        title={A survey of direct methods for sparse linear systems},
        journal={Acta Numerica},
        volume={25},
        year={2016},
        pages={383--566},
        numpages = {184},
        annotate = {\footnotesize
        Abstract: Wilkinson defined a sparse matrix as one with
        enough zeros that it pays to take advantage of them.  This informal yet
        practical definition captures the essence of the goal of direct methods
        for solving sparse matrix problems. They exploit the sparsity of a
        matrix to solve problems economically: much faster and using far less
        memory than if all the entries of a matrix were stored and took part in
        explicit computations. These methods form the backbone of a wide range
        of problems in computational science. A glimpse of the breadth of
        applications relying on sparse solvers can be seen in the origins of
        matrices in published matrix benchmark collections (Duff and Reid
        1979a, Duff, Grimes and Lewis 1989a, Davis and Hu 2011). The goal of
        this survey article is to impart a working knowledge of the underlying
        theory and practice of sparse direct methods for solving linear systems
        and least-squares problems, and to provide an overview of the
        algorithms, data structures, and software available to solve these
        problems, so that the reader can both understand the methods and know
        how best to use them.
        DOI: 
        \href{https://dx.doi.org/10.1017/S0962492916000076}{https://dx.doi.org/10.1017/S0962492916000076}
        }
}

@techreport{spec,
        author={Bulu\c{c}, A. and Mattson, T. and McMillan, S. and Moreira, J. and Yang, C.},
        title={The {GraphBLAS} {C} {API} Specification},
        year={2017},
        note={\href{http://graphblas.org/}{http://graphblas.org/}},
}

@techreport{Kepner2017,
        author={Kepner, J.},
        title={{GraphBLAS} Mathematics},
        year={2017},
        note={
        \href{http://www.mit.edu/~kepner/GraphBLAS/GraphBLAS-Math-release.pdf}{http://www.mit.edu/$\sim$kepner/GraphBLAS/GraphBLAS-Math-release.pdf}
        }
}

@book{KepnerGilbert2011,
        author={Kepner, J. and Gilbert, J.},
        title={Graph Algorithms in the Language of Linear Algebra},
        publisher={SIAM},
        year={2011},
        address={Philadelphia, PA},
        annotate={\footnotesize
        From the preface: Graphs are among the most important
        abstract data types in computer science, and the algorithms that
        operate on them are critical to modern life. Graphs have been shown to
        be powerful tools for modeling complex problems because of their
        simplicity and generality. Graph algorithms are one of the pillars of
        mathematics, informing research in such diverse areas as combinatorial
        optimization, complexity theory, and topology. Algorithms on graphs are
        applied in many ways in today's world—from Web rankings to metabolic
        networks, from finite element meshes to semantic graphs.
        The current exponential growth in graph data has forced a shift to
        parallel computing for executing graph algorithms. Implementing
        parallel graph algorithms and achieving good parallel performance have
        proven difficult. This book addresses these challenges by exploiting
        the well-known duality between a canonical representation of graphs as
        abstract collections of vertices and edges and a sparse adjacency
        matrix representation. This linear algebraic approach is widely
        accessible to scientists and engineers who may not be formally trained
        in computer science. The authors show how to leverage existing parallel
        matrix computation techniques and the large amount of software
        infrastructure that exists for these computations to implement
        efficient and scalable parallel graph algorithms. The benefits of this
        approach are reduced algorithmic complexity, ease of implementation,
        and improved performance.
        DOI: 
        \href{https://dx.doi.org/10.1137/1.9780898719918}{https://dx.doi.org/10.1137/1.9780898719918}},
}

@article{Davis07,
    author={Davis, T. A},
    title={Creating Sparse Finite-Element Matrices in {MATLAB}},
    year={2007},
    month={Mar.},
    note={Loren Shure, editor. Published by {The MathWorks}, Natick, MA.
    \href{http://blogs.mathworks.com/loren/2007/03/01/creating-sparse-finite-element-matrices-in-matlab/}{http://blogs.mathworks.com/loren/2007/03/01/creating-sparse-finite-element-matrices-in-matlab/}},
    editor={Shure, L.},
    journal={Loren on the Art of {MATLAB}},
    publisher={The {MathWorks}, Inc.},
    address={Natick, MA}
    }

@article{Luby86,
    author={Luby, M.},
    title={A simple parallel algorithm for the maximal independent set problem},
    year={1986},
    journal={SIAM J. Comput.},
    volume={15},
    number={4},
    note={\href{https://dx.doi.org/10.1137/0215074}{https://dx.doi.org/10.1137/0215074}}
}

@article{DavisHu11,
        author={Davis, T. A. and Hu, Y.},
        title={The {University} of {Florida} sparse matrix collection},
        journal={ACM Trans. on Math. Software},
        volume={38},
        number={1},
        month=dec,
        year={2011},
        pages={1:1--1:25},
        note={
        \href{https://dx.doi.org/10.1145/2049662.2049663}{https://dx.doi.org/10.1145/2049662.2049663}.
        Now called the SuiteSparse Matrix Collection, at 
        \href{https:sparse.tamu.edu}{https:sparse.tamu.edu}},
        publisher={ACM},
        address={New York, NY, USA},
        keywords={Graph drawing, multilevel algorithms, performance
        evaluation, sparse matrices},
}

@article{Davis18,
        author={Davis, T. A.},
        title={Algorithm 9XX: {SuiteSparse:GraphBLAS}: 
            graph algorithms in the language of sparse linear algebra},
        journal={ACM Trans. on Math. Software},
        volume={(to appear)},
        number={},
        year={2019},
        note={\href{http://faculty.cse.tamu.edu/davis/publications.html}{http://faculty.cse.tamu.edu/davis/publications.html}},
}

@book{Higham,
        author={Higham, N.},
        title={Accuracy and Stability of Numerical Algorithms},
        edition={2nd},
        year={2002},
        publisher={SIAM},
        note={\href{https://dx.doi.org/10.1137/1.9780898718027}{https://dx.doi.org/10.1137/1.9780898718027}}
}

@article{Wathen,
        author={Wathen, A. J.},
        title={Realistic eigenvalue bounds for the {Galerkin} mass matrix},
        journal={{IMA} J. Numer. Anal.},
        volume=7,
        year={1987},
        pages={449--457},
        note={\href{https://dx.doi.org/10.1093/imanum/7.4.449}{https://dx.doi.org/10.1093/imanum/7.4.449} }}

@inproceedings{WolfBerryStark15,
        author={Wolf, M. M. and Berry, J. W. and Stark, D. T.},
        title={A task-based linear algebra building blocks approach for scalable graph analytics},
        year={2015},
        booktitle={IEEE HPEC'15},
        publisher={IEEE},
        pages={1--6}
}

@inproceedings{Davis18b,
        author={Davis, T. A.},
        title={Graph algorithms via {SuiteSparse:GraphBLAS}: triangle counting and {K}-truss},
        year={2018},
        booktitle={IEEE HPEC'18},
        note={Grand Challenge Innovation Award.
            See \href{http://www.ieee-hpec.org/}{http://www.ieee-hpec.org/}.},
        publisher={IEEE},
}

@inproceedings{DavisAznavehKolodziej19,
        author={Davis, T. A. and Aznaveh, M. and Kolodziej, S.},
        title={Write Quick, Run Fast: Sparse Deep Neural Network in 20 Minutes of
            Development Time via {SuiteSparse:GraphBLAS}},
        year={2019},
        note={Grand Challenge Champion, for high performance.
            See \href{http://www.ieee-hpec.org/}{http://www.ieee-hpec.org/}.},
        booktitle={IEEE HPEC'19},
        publisher={IEEE},
}

@inproceedings{Mattson19,
        author={Mattson, T. and Davis, T. A. and Kumar, M. and Bulu\c{c}, A. and McMillan, S. and
            Moreira, J. and Yang, C.},
        title={{LAGraph}: a community effort to collect graph algorithms built on top of the {GraphBLAS}},
        year={2019},
        booktitle={GrAPL'19: Workshop on Graphs, Architectures, Programming, and Learning},
        note={\href{https://hpc.pnl.gov/grapl/previous/2019}{https://hpc.pnl.gov/grapl/previous/2019},
            part of IPDPS'19, at \href{http://www.ipdps.org/ipdps2019} {http://www.ipdps.org/ipdps2019}},
        month={May},
        publisher={IEEE},
}

@inproceedings{Davis20,
  author = {Mohsen Aznaveh and
      Jinhao Chen and
      Timothy A. Davis and
      B{\'{a}}lint Hegyi and
      Scott P. Kolodziej and
      Timothy G. Mattson and
      G{\'{a}}bor Sz{\'{a}}rnyas},
  title = {Parallel {GraphBLAS} with {OpenMP}},
  year = {2020},
  booktitle = {CSC20, SIAM Workshop on Combinatorial Scientific Computing},
  note = {(accepted) \href{https://www.siam.org/conferences/cm/conference/csc20}{https://www.siam.org/conferences/cm/conference/csc20}},
  publisher = {{SIAM}},
}


@article{Burkhardt16,
        author={Burkhardt, P.},
        title={Graphing trillions of triangles},
        journal={Information Visualization},
        volume={16},
        pages={157--166},
        year={2016},
        note={
        \href{https://dx.doi.org/10.1177/1473871616666393}{https://dx.doi.org/10.1177/1473871616666393} }
}

@inproceedings{AzadBulucGilbert15,
        author={Azad, A. and Bulu\c{c}, A. and Gilbert, J.},
        title={Parallel triangle counting and enumeration using matrix algebra},
        booktitle={2015 IEEE International Parallel and Distributed Processing Symposium Workshop, IPDPSW ’15},
        pages={804--811},
        year={2015},
        publisher={IEEE Computer Society},
}

@article{Cohen09,
        author={Cohen, J.},
        title={Graph twiddling in a mapreduce world},
        journal={Computing in Science and Engineering},
        volume={11},
        number={4},
        pages={29--41},
        month={July},
        year={2009}
}

@INPROCEEDINGS{WolfDeveciBerryHammondRajamanickam17,
    author={Wolf, M. M. and Deveci, M. and Berry, J. W. and Hammond, S. D. and Rajamanickam, S.},
    booktitle={2017 IEEE High Performance Extreme Computing Conference (HPEC)},
    title={Fast linear algebra-based triangle counting with {KokkosKernels}},
    year={2017},
    volume={},
    number={},
    pages={1-7},
    annotate={\footnotesize
    Triangle counting serves as a key building block for a set of
    important graph algorithms in network science. In this paper, we address
    the IEEE HPEC Static Graph Challenge problem of triangle counting, focusing
    on obtaining the best parallel performance on a single multicore node. Our
    implementation uses a linear algebra-based approach to triangle counting
    that has grown out of work related to our miniTri data analytics
    miniapplication and our efforts to pose graph algorithms in the
    language of linear algebra. We leverage KokkosKernels to implement this
    approach efficiently on multicore architectures. Our performance results
    are competitive with the fastest known graph traversal-based approaches and
    are significantly faster than the Graph Challenge reference
    implementations, up to 670,000 times faster than the C++ reference and
    10,000 times faster than the Python reference on a single Intel Haswell
    node.},
    keywords={Algorithm design and analysis;C++ languages;Computer
    architecture;Kernel;Libraries;Linear algebra;Sparse matrices},
    note={
    \href{https://dx.doi.org/10.1109/HPEC.2017.8091043}{https://dx.doi.org/10.1109/HPEC.2017.8091043}
    },
    ISSN={},
    month={Sept},
}

@INPROCEEDINGS{BulucMattsonMcMillanMoreiraYang17, 
    author={A. Bulu\c{c} and T. Mattson and S. McMillan and J. Moreira and C. Yang}, 
    booktitle={2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
    title={Design of the {GraphBLAS} {API} for {C}}, 
    year={2017}, 
    volume={}, 
    number={}, 
    pages={643-652}, 
    keywords={C language;application program interfaces;formal
    specification;graph theory;linear algebra;C language specification
    subcommittee;GraphBLAS API;GraphBLAS Forum;application programming
    interface;betweenness centrality algorithm;design;graph
    computations;linear-algebraic building blocks;mathematical
    specification;Additives;Linear algebra;Programming;Semantics;Sparse
    matrices}, 
    note={\href{https://dx.doi.org/10.1109/IPDPSW.2017.117}{https://dx.doi.org/10.1109/IPDPSW.2017.117} },
    month={May},
}

@article{Gustavson78,
        author={Gustavson, F. G.},
        year={1978},
        title={Two Fast Algorithms for Sparse Matrices: Multiplication and Permuted Transposition},
        journal=TOMS,
        volume={4},
        number={3},
        pages={250--269},
        note={
        \href{https://dx.doi.org/10.1145/355791.355796}{https://dx.doi.org/10.1145/355791.355796}},
}

@article{GilbertMolerSchreiber92,
        author={Gilbert, J. R. and Moler, C. and Schreiber, R.},
        title={Sparse matrices in {MATLAB}:  design and implementation},
        journal=SIMAX,
        year={1992},
        volume={13},
        number={1},
        pages={333-356},
        url={ http://dx.doi.org/10.1137/0613024 },
}

@inproceedings{Beamer:2012:DOB,
	title={Direction-optimizing Breadth-First Search},
	author={Beamer, Scott and Asanovic, Krste and Patterson, David},
	booktitle={International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
	pages={1--10},
	year={2012},
}

@inproceedings{Yang:2018:IPE,
	title =	 {Implementing Push-Pull Efficiently in {GraphBLAS}},
	author =	 {Carl Yang and Ayd\i{}n Bulu\c{c} and John D. Owens},
	booktitle =	 {Proceedings of the International Conference on
	Parallel Processing},
	series =	 {ICPP 2018},
	month =	 aug,
	year =	 2018,
	pages =	 {89:1--89:11},
	doi =		 {10.1145/3225058.3225122},
	code =	 {https://github.com/owensgroup/push-pull}
}

@inproceedings{10.1145/3229710.3229720,
author = {Nagasaka, Yusuke and Matsuoka, Satoshi and Azad, Ariful and Bulu\c{c}, Aydundefinedn},
title = {High-Performance Sparse Matrix-Matrix Products on Intel KNL and Multicore Architectures},
year = {2018},
isbn = {9781450365239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3229710.3229720},
doi = {10.1145/3229710.3229720},
booktitle = {Proceedings of the 47th International Conference on Parallel Processing Companion},
articleno = {Article 34},
numpages = {10},
keywords = {Intel KNL, SpGEMM, Sparse matrix},
location = {Eugene, OR, USA},
series = {ICPP ’18}
}



% [2] Yusuke Nagasaka, Satoshi Matsuoka, Ariful Azad, and Aydın Buluç. 2018.
% High-Performance Sparse Matrix-Matrix Products on Intel KNL and Multicore
% Architectures. In Proc. 47th Intl. Conf. on Parallel Processing (ICPP '18).
% Association for Computing Machinery, New York, NY, USA, Article 34, 1–10.
% DOI:https://doi.org/10.1145/3229710.3229720
